{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzXBieRM9Kfh"
      },
      "source": [
        "# Paso #1: IMPORTAR LIBRERÍAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9n57F309eOq"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/i4n134sqzu7psry/fotos%20procesadas.zip?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HypAU829fn-"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/u5fu6o8285ebsne/Fotos%20TFM.zip?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6v3JtBC9Kfm"
      },
      "outputs": [],
      "source": [
        "!unzip Fotos\\ TFM.zip\\?dl\\=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbaEe4kbIRZm"
      },
      "outputs": [],
      "source": [
        "!unzip fotos\\ procesadas.zip\\?dl\\=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSLFlOkZ9Kfp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMg3eqGX9Kfq"
      },
      "outputs": [],
      "source": [
        "# Funciones y metodos reutilizables\n",
        "def elem2dict(node):\n",
        "    \"\"\"\n",
        "    Convert an xml.ElementTree node tree into a dict.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "\n",
        "    for element in node:\n",
        "        key = element.tag\n",
        "        if '}' in key:\n",
        "            # Remove namespace prefix\n",
        "            key = key.split('}')[1]\n",
        "\n",
        "        if node.attrib:\n",
        "            result['@attribs'] = dict(node.items())\n",
        "\n",
        "        # Process element as tree element if the inner XML contains non-whitespace content\n",
        "        if element.text and element.text.strip():\n",
        "            value = element.text\n",
        "        else:\n",
        "            value = elem2dict(element)\n",
        "\n",
        "        # Check if a node with this name at this depth was already found\n",
        "        if key in result:\n",
        "            if type(result[key]) is not list:\n",
        "                # We've seen it before, but only once, we need to convert it to a list\n",
        "                tempvalue = result[key].copy()\n",
        "                result[key] = [tempvalue, value]\n",
        "            else:\n",
        "                # We've seen it at least once, it's already a list, just append the node's inner XML\n",
        "                result[key].append(value)\n",
        "        else:\n",
        "            # First time we've seen it\n",
        "            result[key] = value\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_data_imgLabel(imgLabel):\n",
        "    x = imgLabel[\"bndbox\"][\"xmin\"]\n",
        "    y = imgLabel[\"bndbox\"][\"ymin\"]\n",
        "    width = imgLabel[\"bndbox\"][\"xmax\"]\n",
        "    height = imgLabel[\"bndbox\"][\"ymax\"]\n",
        "\n",
        "    return x,y, width, height\n",
        "\n",
        "# Funcion para redimensionar la imagen  a (512, 512)\n",
        "# para redimensionar la imagen  a (512, 512)\n",
        "def resize(x):\n",
        "  return cv2.resize(x, dsize=(widthImage, heightImage), interpolation = cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYYsXr5y9Kfr"
      },
      "outputs": [],
      "source": [
        "# Importamos los paquetes necesarios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from PIL import *\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.python.keras import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from xml.etree import ElementTree as ET\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Definimos variables generales\n",
        "# Ruta de la data y capertas dentro de esta\n",
        "dataPath = '/content/Fotos TFM'\n",
        "dataPathXML = '/content/fotos procesadas'\n",
        "typeLeavesList = os.listdir(dataPathXML)\n",
        "\n",
        "widthImage = 224\n",
        "heightImage = 224\n",
        "quantitytoProcess = 1000\n",
        "\n",
        "# data\n",
        "labels = []\n",
        "leavesData = []\n",
        "labelCounter = 0\n",
        "\n",
        "# Leemos la información de los Json en las carpetas, para \n",
        "# obtener las coordenadas de las imagenes etiquetadas.\n",
        "listCount = []\n",
        "dataToProcess = []\n",
        "\n",
        "for nameDir in typeLeavesList:\n",
        "    leavePathXML = dataPathXML + '/' + nameDir\n",
        "    leavePathImg = dataPath + '/' + nameDir\n",
        "\n",
        "    if \"Sanas\" == nameDir:\n",
        "      labelCounter = 0\n",
        "\n",
        "    if \"Enfermas\" == nameDir:\n",
        "      labelCounter = 1\n",
        "\n",
        "    # lista de archivos .json con las etiquetas de las imagenes\n",
        "    listXML =  [f for f in os.listdir(leavePathXML) if f.endswith('.xml')]\n",
        "\n",
        "    listXML = listXML[:quantitytoProcess]\n",
        "\n",
        "    countFilesXML = len([name for name in listXML ])\n",
        "    print('Cantidad de imágenes:', nameDir)\n",
        "    print(countFilesXML)\n",
        "\n",
        "    sample20ListXML = random.sample(listXML, 20)\n",
        "\n",
        "    # Cantidad de archivos a procesar\n",
        "    listCount.append(countFilesXML)\n",
        "\n",
        "    for fileXML in listXML:\n",
        "        listFiltered = list(filter(lambda x: x[\"label\"] == labelCounter, dataToProcess))\n",
        "        if len(listFiltered) > quantitytoProcess:\n",
        "            continue\n",
        "\n",
        "        xmlParsed = ET.parse(leavePathXML + '/'+ fileXML).getroot()\n",
        "        xmlDict = elem2dict(xmlParsed)\n",
        "        imageName = xmlDict[\"filename\"]\n",
        "\n",
        "        if \"object\" not in xmlDict:\n",
        "            continue\n",
        "\n",
        "        objectImgLabel = xmlDict[\"object\"]\n",
        "\n",
        "        # Obtenemos la imagen completa\n",
        "        image = cv2.imread(leavePathImg+'/'+ imageName)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if (type(objectImgLabel) == list):\n",
        "            for imgLabel in objectImgLabel:\n",
        "                x, y, width, height = get_data_imgLabel(imgLabel)\n",
        "                roi = image[int(y):int(height), int(x):int(width)]\n",
        "\n",
        "                leafData = {\n",
        "                    \"filenameImg\": imageName,\n",
        "                    \"filenameXML\": fileXML,\n",
        "                    \"label\" : labelCounter,\n",
        "                    \"roi\": resize(roi)\n",
        "                }\n",
        "                dataToProcess.append(leafData)\n",
        "\n",
        "        else:\n",
        "            x, y, width, height = get_data_imgLabel(objectImgLabel)\n",
        "            roi = image[int(y):int(height), int(x):int(width)]\n",
        "            leafData = {\n",
        "                \"filenameImg\": imageName,\n",
        "                \"filenameXML\": fileXML,\n",
        "                \"label\" : labelCounter,\n",
        "                \"roi\": resize(roi)\n",
        "            }\n",
        "            dataToProcess.append(leafData)\n",
        "\n",
        "\n",
        "newListEnfermas = filter(lambda x: x[\"label\"] == 1, dataToProcess)\n",
        "newListSanas = filter(lambda x: x[\"label\"] == 0, dataToProcess)\n",
        "\n",
        "listEnfermas = list(newListEnfermas)\n",
        "listSanas = list(newListSanas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnwrVqZf2GJi"
      },
      "outputs": [],
      "source": [
        "# # Mostrar las primeras 40 imágenes enfermas\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "for i in range(40):\n",
        "    image = listEnfermas[i][\"roi\"]\n",
        "    ax = fig.add_subplot(5, 8, i + 1)\n",
        "    ax.imshow(image)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmkOoWL44IQT"
      },
      "outputs": [],
      "source": [
        "# # Mostrar las primeras 40 imágenes SANAS\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "for i in range(40):\n",
        "    image = listSanas[i][\"roi\"]\n",
        "    ax = fig.add_subplot(5, 8, i + 1)\n",
        "    ax.imshow(image)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52KwfEXh9Kfu"
      },
      "outputs": [],
      "source": [
        "# Visualiacion de cantidad de imagenes por clasificación - Enfermas / Sanas\n",
        "xbarPlot = [\"Enfermas\", \"Sanas\"]\n",
        "ybarPlot = [len(listEnfermas), len(listSanas)]\n",
        "\n",
        "plt.figure(figsize = (5,5))\n",
        "sns.barplot(x = xbarPlot, y = ybarPlot )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQWn-w5l9Kfv"
      },
      "outputs": [],
      "source": [
        "print('Número de etiquetas 1 (Enfermas): ', len(listEnfermas))\n",
        "print('Número de etiquetas 0(Sanas): ', len(listSanas))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162SGTZ19Kfw"
      },
      "source": [
        "# Paso #2: VISUALIZACIÓN DE IMÁGENES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KHZ7xmk9Kfx"
      },
      "source": [
        "# Paso #3: PREPROCESADOR DE LAS IMÁGENES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETRCBnKI9Kfx"
      },
      "outputs": [],
      "source": [
        "# Dividir el dataframe en características y etiquetas para la clasificación\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "X = np.array([x[\"roi\"] for x in dataToProcess])\n",
        "y = to_categorical([x[\"label\"] for x in dataToProcess] )\n",
        "\n",
        "# # Visualizamos los pixeles de las imagenes\n",
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnJb6nje9Kfy"
      },
      "outputs": [],
      "source": [
        "# Visualizamos las etiquetas\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0yt2UaW9Kfy"
      },
      "outputs": [],
      "source": [
        "# Revisando la dimensionalidad de X\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke3Du8oi9Kfz"
      },
      "outputs": [],
      "source": [
        "X = np.stack(X, axis = 0)\n",
        "# aqui era uno, pero algo ha pasado y se cambio a 3\n",
        "X = X.reshape(len(listEnfermas)+len(listSanas) , 224, 224, 3)\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeCfLOMO9Kfz"
      },
      "outputs": [],
      "source": [
        "# Dividir el dataframe en conjunto de entrenamiento, test y validación\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Obtenemos el conjunto de entrenamiento y el conjunto de Test\n",
        "X_train, X_Test, y_train, y_Test = train_test_split(X, y, test_size = 0.4, shuffle = True)\n",
        "\n",
        "# Del conjunto de Test, obtenemos una parte para el conjunto de validaciòn, el 50% del conjunto de Test\n",
        "X_val, X_Test, y_val, y_Test = train_test_split(X_Test, y_Test, test_size = 0.6, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62QlYsREeU0k"
      },
      "outputs": [],
      "source": [
        "# Limpiar memoria\n",
        "del dataToProcess\n",
        "del X\n",
        "del y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5NDTFVc9Kfz"
      },
      "outputs": [],
      "source": [
        "print(\"Conjunto de validación\")\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(\"Conjunto de Test\")\n",
        "print(X_Test.shape, y_Test.shape)\n",
        "print(\"Conjunto de Entrenamiento\")\n",
        "print(X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3_vU2Eg9Kf0"
      },
      "source": [
        "# Paso #4: NORMALIZACIÓN DE LOS DATOS Y PREPARACIÓN PARA EL ENTRENAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlkagCwo9Kf0"
      },
      "outputs": [],
      "source": [
        "# # Pre Procesado de Imágenes\n",
        "# with tf.device('/gpu:0'):\n",
        "#   X_train = X_train/255\n",
        "#   X_val   = X_val /255\n",
        "#   X_Test  = X_Test/255\n",
        "\n",
        "#   X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J_wJKcX9Kf0"
      },
      "source": [
        "# Paso #3: AUMENTACIÓN DE LAS IMÁGENES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vADmgAr39Kf1"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    # rotation_range=90,\n",
        "    # width_shift_range=0.05,\n",
        "    # height_shift_range=0.2,\n",
        "    # shear_range=0.2,\n",
        "    # zoom_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        "    # vertical_flip = True,\n",
        "    brightness_range = [1.1, 1.15]\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=90,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # shear_range=0.2,\n",
        "    # zoom_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        "    # vertical_flip = True,\n",
        "    brightness_range = [1.1, 1.15]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu0XfnG59Kf1"
      },
      "source": [
        "# TAREA #6: CONSTRUIR UN MODELO DE DEEP LEARNING(CNN) DE RESTNET(RED RESIDUAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11UbsJ789Kf2"
      },
      "outputs": [],
      "source": [
        "# Se define a nivel de código, el bloque de capa red residual (RESTNET)\n",
        "# Lo usaremos luego en a la arquitectura principal del modelo\n",
        "\n",
        "def res_block_v2(X, filter, stage):\n",
        "\n",
        "  # Bloque Convolucional\n",
        "  X_copy = X\n",
        "\n",
        "  f1 , f2, f3 = filter\n",
        "\n",
        "  # Camino Principal\n",
        "  X = layers.Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.MaxPool2D((2,2))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
        "\n",
        "\n",
        "  # Camino Corto\n",
        "  X_copy = layers.Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
        "  X_copy = layers.MaxPool2D((2,2))(X_copy)\n",
        "  X_copy = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
        "\n",
        "  # Añadir\n",
        "  X = layers.Add()([X,X_copy])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # Bloque de Identidad 1\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Camino Principal\n",
        "  X = layers.Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
        "\n",
        "  # Añadir\n",
        "  X = layers.Add()([X,X_copy])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # Bloque de Identidad 2\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Camino Principal\n",
        "  X = layers.Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = layers.BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
        "\n",
        "  # Añadir\n",
        "  X = layers.Add()([X,X_copy])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-W05C3P9Kf2"
      },
      "outputs": [],
      "source": [
        "# Arquietectura principal para CNN con RestNet\n",
        "\n",
        "# Debo usar pixeles mas grandes como 224 x 224\n",
        "input_shape_v2 = (224, 224, 3)\n",
        "\n",
        "# Tamaño del tensor de entrada\n",
        "X_input2 = keras.Input(input_shape_v2)\n",
        "\n",
        "# Zero-padding\n",
        "X = layers.ZeroPadding2D((3, 3))(X_input2)\n",
        "\n",
        "# 1 - Fase\n",
        "X = layers.Conv2D(64, (7, 7), strides= (2, 2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "X = layers.BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
        "X = layers.Activation('relu')(X)\n",
        "X = layers.MaxPooling2D((3, 3), strides= (2, 2))(X)\n",
        "\n",
        "# 2 - Fase\n",
        "X = res_block_v2(X, filter= [64, 64, 256], stage= 2)\n",
        "\n",
        "# 3 - Fase\n",
        "X = res_block_v2(X, filter= [128, 128, 512], stage= 3)\n",
        "\n",
        "# 4 - Fase\n",
        "X = res_block_v2(X, filter= [256, 256, 1024], stage= 4)\n",
        "\n",
        "# Average Pooling\n",
        "X = layers.AveragePooling2D((4, 4), name = 'Averagea_Pooling')(X)\n",
        "\n",
        "# Capa Final\n",
        "X = layers.Flatten()(X)\n",
        "X = layers.Dense(2, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "\n",
        "\n",
        "model_clasification_leaves = keras.Model( inputs= X_input2, outputs = X, name = 'Resnet26')\n",
        "\n",
        "model_clasification_leaves.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRlikoZg9Kf3"
      },
      "outputs": [],
      "source": [
        "from time import gmtime, strftime\n",
        "# Usamos la parada temprana para salir del entenamiento si el error de validación\n",
        "# no decrece después de cierto número de epochs (paciencia)\n",
        "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
        "fileTime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
        "print(fileTime)\n",
        "# Guardamos el mejor modelo con menor error de validación\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath = \"/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/Leaves_Clasification_weights \"+fileTime+\".hdf5\",\n",
        "    verbose = 1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iczl5C2g9Kf3"
      },
      "outputs": [],
      "source": [
        "print(\"Conjunto de Entrenamiento\")\n",
        "print(X_train.shape, y_train.shape)\n",
        "model_clasification_leaves.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "valid_generator = valid_datagen.flow(\n",
        "    X_val, y_val,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow(\n",
        "    X_Test, y_Test,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmTufBxn5_60"
      },
      "outputs": [],
      "source": [
        "# Visualizar algunas imágenes generadas\n",
        "\n",
        "# # Mostrar las primeras 40 imágenes SANAS\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in train_generator:\n",
        "    for i in range(40):\n",
        "        ax = fig.add_subplot(5, 8, i + 1)\n",
        "        ax.imshow(images[i])\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjX1aonjIJev"
      },
      "outputs": [],
      "source": [
        "# TEST\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in test_generator:\n",
        "    for i in range(100):\n",
        "        ax = fig.add_subplot(10, 10, i + 1)\n",
        "        ax.imshow(images[i])\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4npl0w5X0Tg"
      },
      "outputs": [],
      "source": [
        "# Cargando Mejor Modelo Existente\n",
        "\n",
        "model_clasification_leaves = load_model(\"/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/leaf_model Accuracy 0.978935718536377 --2023-07-09 15:04:06.h5\")\n",
        "\n",
        "score = model_clasification_leaves.evaluate(X_Test, y_Test)\n",
        "print('Accuracy en la fase de Test: {}'.format(score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEMEwSi49Kf3"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "\thistory = model_clasification_leaves.fit(X_train, y_train, batch_size=batch_size,\n",
        "\t\t validation_data=(X_val, y_val), steps_per_epoch=len(X_train) // batch_size,\n",
        "\t\tepochs= 100, callbacks=[checkpointer, earlystopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnkfQmTxjIcK"
      },
      "outputs": [],
      "source": [
        "modeloCNN2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(250, activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqn_AYxwjPbC"
      },
      "outputs": [],
      "source": [
        "modeloCNN2.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_-Hkmw0jVam"
      },
      "outputs": [],
      "source": [
        "# modeloCNN2.fit(X_train, y_train, batch_size=32,\n",
        "#                 validation_data=(X_val, y_val),\n",
        "#                 epochs=100,\n",
        "#                 steps_per_epoch=len(X_train) // 32,\n",
        "#                 callbacks=[checkpointer, earlystopping])\n",
        "with tf.device('/gpu:0'):\n",
        "  modeloCNN2.fit(\n",
        "      train_generator,\n",
        "      epochs=100,\n",
        "      validation_data=valid_generator,\n",
        "      callbacks=[checkpointer, earlystopping]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzDs_AGzqcWF"
      },
      "outputs": [],
      "source": [
        "fileTime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
        "print(fileTime)\n",
        "modeloCNN2.save('/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/leaf_model '+fileTime+'.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsd6f6VW9Kf4"
      },
      "outputs": [],
      "source": [
        "predictions = model_clasification_leaves.predict(X_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjCpvpTSg98R"
      },
      "outputs": [],
      "source": [
        "X_Test_nuevo  = X_Test.copy()\n",
        "X_Test_nuevo  = X_Test_nuevo/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7_3z9EEP_Ge"
      },
      "outputs": [],
      "source": [
        "score = model_clasification_leaves.evaluate(X_Test, y_Test)\n",
        "score_acurracy = score[1]\n",
        "print('Accuracy en la fase de Test: {}'.format(score_acurracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLTXNK4E9Kf4"
      },
      "outputs": [],
      "source": [
        "fileTime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
        "print(fileTime)\n",
        "model_clasification_leaves.save('/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/leaf_model Accuracy '+str(score_acurracy)+ \" --\"+fileTime+'.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jroeeAb_8Ym"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyrP2KhF9Kf4"
      },
      "source": [
        "# Paso #16: EVALUAR LA EFICACIA DEL MODELO CLASIFICACIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QhXHSCp9KgA"
      },
      "source": [
        "# Paso #16: EVALUAR EL MODELO DE CLASIFICACIÓN (MATRIZ DE CONFUSIÓN, ACIERTO, PRECISIÓN Y RECUPERACIÓN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzNgCHMQ9KgA"
      },
      "outputs": [],
      "source": [
        "model_leaf = load_model('leaf_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YhiRh0a9KgA"
      },
      "outputs": [],
      "source": [
        "score = model_leaf.evaluate(X_Test, y_Test)\n",
        "print('Accuracy en la fase de Test: {}'.format(score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO6aQ_e69KgA"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH5kH2xl9KgB"
      },
      "outputs": [],
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTTZ6Gxz9KgB"
      },
      "outputs": [],
      "source": [
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs, accuracy, 'bo', label='Accuracy en el Entrenamiento')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Accuracy en la Validación')\n",
        "plt.title('ACCURACY')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n053F4hx9KgB"
      },
      "outputs": [],
      "source": [
        "# predicted_classes = model.predict_classes(X_test)\n",
        "predicted_classes = np.argmax(model_clasification_leaves.predict(X_Test), axis=-1)\n",
        "y_true = np.argmax(y_Test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLiEWYyd9KgB"
      },
      "outputs": [],
      "source": [
        "label_to_text = {1:'Enferma', 0:'Sana'}\n",
        "\n",
        "L = 5\n",
        "W = 5\n",
        "\n",
        "fig, axes = plt.subplots(L, W, figsize = (24, 24))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L*W):\n",
        "    axes[i].imshow(X_Test[i])\n",
        "    axes[i].set_title('Predicción = {}\\n Verdadera = {}'.format(label_to_text[predicted_classes[i]], label_to_text[y_true[i]]))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg35E9jLV6NB"
      },
      "outputs": [],
      "source": [
        "image_hoja_sana_internet = cv2.imread('/content/copia-hoja-sana.jpg')\n",
        "image_hoja_sana_internet = cv2.cvtColor(image_hoja_sana_internet, cv2.COLOR_BGR2RGB)\n",
        "image_hoja_sana_internet = resize(image_hoja_sana_internet)\n",
        "plt.imshow(image_hoja_sana_internet)\n",
        "plt.axis('off')  # Opcional: ocultar los ejes x e y\n",
        "plt.show()\n",
        "image_hoja_sana_internet = image_hoja_sana_internet.reshape(1, 224, 224, 3)\n",
        "predicted_sana_internet = np.argmax(model_clasification_leaves.predict(image_hoja_sana_internet), axis=-1)\n",
        "label_to_text =  {1:'Enferma', 0:'Sana'}\n",
        "text_prediction = label_to_text[predicted_sana_internet[0]]\n",
        "print(\"Prediccion es: \")\n",
        "print(text_prediction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9X7_MNPkfp3"
      },
      "outputs": [],
      "source": [
        "model_clasification_leaves = load_model(\"/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/leaf_model Accuracy 0.978935718536377 --2023-07-09 15:04:06.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_aWQgHxZs7d"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "# URL de la imagen\n",
        "# url_sana = 'https://img.freepik.com/fotos-premium/mango-hoja-verde-aislado-sobre-fondo-blanco_42033-484.jpg'\n",
        "# url_enferma = 'https://agrotrapiche.com/wp-content/uploads/2019/11/4-0-1-1024x1024.png'\n",
        "# url_enferma02 = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQFcEN2V8TODwSjglUdoz8r6NhpKW2o0NE9MMg27Tid684CdeMBhHkgCXEW2lAG3SsL9rE&usqp=CAU'\n",
        "url_enferma03 = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQpR_Ax-iye-oPsjwa84_0spB05cj7iPE3iSp-qKis6DOmQe-QIrhSjK-4whLEeE4pyWUM&usqp=CAU'\n",
        "\n",
        "# Descargar la imagen desde la URL\n",
        "resp = urllib.request.urlopen(url_enferma03)\n",
        "image_bytes = np.array(bytearray(resp.read()), dtype=np.uint8)\n",
        "# Decodificar la imagen utilizando OpenCV\n",
        "image_hoja_sana_internet = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "image_hoja_sana_internet = cv2.cvtColor(image_hoja_sana_internet, cv2.COLOR_BGR2RGB)\n",
        "if image is not None:\n",
        "    # La imagen se ha leído correctamente\n",
        "    image_hoja_sana_internet = resize(image_hoja_sana_internet)\n",
        "    plt.imshow(image_hoja_sana_internet)\n",
        "    plt.axis('off')  # Opcional: ocultar los ejes x e y\n",
        "    plt.show()\n",
        "    image_hoja_sana_internet = image_hoja_sana_internet.reshape(1, 224, 224, 3)\n",
        "    predicted_sana_internet = np.argmax(model_clasification_leaves.predict(image_hoja_sana_internet), axis=-1)\n",
        "    label_to_text =  {1:'Enferma', 0:'Sana'}\n",
        "    text_prediction = label_to_text[predicted_sana_internet[0]]\n",
        "    print(\"Predicción es: \")\n",
        "    print(text_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vovNGZpmyavj"
      },
      "outputs": [],
      "source": [
        "sanas_internet = [\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTURlJJCsTK-Owkiji6cwz3STl6iVlMTWSZNdl9NHuL_cvNZdClNTUw1LAzC_meduC19IA&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT0WM435LT6Fv-YEfUov-Q78GpAv_911PgZBaU2aEcx_UMs_idUot9B1sIzz78weUKb7UM&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS2VKgCbYcK6UndVyCPBIaD2pgf10SQXtilgQjjnYFSzzuC0SNUFSd8JdFi9Se7jiHeZ2M&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR_xooBL5Lf-TAIwnf1ldsy_DXpg8vlFUeX44YHa3FxeMRuPXOq8salteB8H6WQdnT7koU&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSnjVPiVbVNfkdDbpR0qsDjnHL9pBeiWyrLntQ2kKP4lviT1fA7yLu2uc0JF4W7y411vzU&usqp=CAU\",\n",
        "  \"https://us.123rf.com/450wm/yaryhee/yaryhee1606/yaryhee160600015/59215477-la-hoja-de-mango.jpg\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTqY6zWC_ejKmmMB4y0Nj5hLKkMk0X9lP0fjMPUSZoAFJ-DSqX_fNUlzsxW2bPlDlrDnQE&usqp=CAU\",\n",
        "  \"https://us.123rf.com/450wm/aoo3771/aoo37711402/aoo3771140200369/26098871-mango-deja-aislado-en-blanco-imagen-de-fondo-en.jpg\",\n",
        "  \"https://cdn.xxl.thumbs.canstockphoto.es/cierra-la-hoja-de-mango-sobre-fondo-blanco-almacen-de-im%C3%A1genes_csp58784959.jpg\"\n",
        "]\n",
        "\n",
        "for imagen_url in sanas_internet:\n",
        "  # Descargar la imagen desde la URL\n",
        "  resp = urllib.request.urlopen(imagen_url)\n",
        "  image_bytes = np.array(bytearray(resp.read()), dtype=np.uint8)\n",
        "  # Decodificar la imagen utilizando OpenCV\n",
        "  image_hoja_sana_internet = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "  image_hoja_sana_internet = cv2.cvtColor(image_hoja_sana_internet, cv2.COLOR_BGR2RGB)\n",
        "  if image is not None:\n",
        "      # La imagen se ha leído correctamente\n",
        "      image_hoja_sana_internet = resize(image_hoja_sana_internet)\n",
        "      plt.imshow(image_hoja_sana_internet)\n",
        "      plt.axis('off')  # Opcional: ocultar los ejes x e y\n",
        "      plt.show()\n",
        "      image_hoja_sana_internet = image_hoja_sana_internet.reshape(1, 224, 224, 3)\n",
        "      predicted_sana_internet = np.argmax(model_clasification_leaves.predict(image_hoja_sana_internet), axis=-1)\n",
        "      label_to_text =  {1:'Enferma', 0:'Sana'}\n",
        "      text_prediction = label_to_text[predicted_sana_internet[0]]\n",
        "      print(\"Predicción es: \")\n",
        "      print(text_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_-1b8CO0daR"
      },
      "outputs": [],
      "source": [
        "enfermas_internet = [\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcReuBlyPTc6q_7YCkYpqRS8bRDsLWGZcO0PPxtraUc6G1OS8fit3TPXPT6cO-D0dHDuxhg&usqp=CAU\",\n",
        "  \"https://content.peat-cloud.com/w400/bacterial-black-spot-of-mango-mango-1552661351.jpg\",\n",
        "  \"https://www.shutterstock.com/image-photo/alternaria-leaf-spot-on-mango-260nw-1691257909.jpg\",\n",
        "  \"https://www.shutterstock.com/shutterstock/photos/1946321845/display_1500/stock-photo-anthracnose-disease-on-mango-leaf-caused-by-colletotrichum-gloeosporioides-on-white-background-1946321845.jpg\",\n",
        "  \"https://live.staticflickr.com/874/42387298952_23197af4c0_b.jpg\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnjXb_R8n1MjHUI1MIGrOfv0zo4YVh5Vv6tzzWAFb-EuYyMXaJOKHFCPW_Y0wp1ME3AyI&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSjdTqCNdekTir1C7jpi5CyO-n_wRLOeYSRO96mdaVEiUz99g7GftMoTp1DEUy7BE_Da0M&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTxeqWWq2L_12_C1ZuUYS7-MZz6sASANFHX4V5F-EMLC3FYr_pArPCGncByfrwnJf_rNVc&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRm5JTzwfAdyn-hoQAnDk0PGEpinNsQvkvGTfcACZz56RqCjOBvxDcPciPO5m-UjdJLZwM&usqp=CAU\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSpP3r15kW_8a4n1UuKMVJhK9H-CzuKNP_FC7Te4Iz2T0d5JsfyLES0DWM3OlVlUxE9Iz4&usqp=CAU\",\n",
        "  \"https://content.peat-cloud.com/thumbnails/phoma-blight-mango-1550581511.jpg\",\n",
        "  \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSE7Hvj9EhsxOhtxW9u8RvOIniZHyMqOvWQdw&usqp=CAU\",\n",
        "  \"https://www.shutterstock.com/image-photo/plant-disease-mango-leaves-anthracnose-260nw-729865960.jpg\",\n",
        "  \"https://www.shutterstock.com/image-photo/fungus-on-mango-leaves-anthracnose-260nw-1851072517.jpg\",\n",
        "\n",
        "]\n",
        "\n",
        "for imagen_url in enfermas_internet:\n",
        "  # Descargar la imagen desde la URL\n",
        "  resp = urllib.request.urlopen(imagen_url)\n",
        "  image_bytes = np.array(bytearray(resp.read()), dtype=np.uint8)\n",
        "  # Decodificar la imagen utilizando OpenCV\n",
        "  image_hoja_sana_internet = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "  image_hoja_sana_internet = cv2.cvtColor(image_hoja_sana_internet, cv2.COLOR_BGR2RGB)\n",
        "  if image is not None:\n",
        "      # La imagen se ha leído correctamente\n",
        "      image_hoja_sana_internet = resize(image_hoja_sana_internet)\n",
        "      plt.imshow(image_hoja_sana_internet)\n",
        "      plt.axis('off')  # Opcional: ocultar los ejes x e y\n",
        "      plt.show()\n",
        "      image_hoja_sana_internet = image_hoja_sana_internet.reshape(1, 224, 224, 3)\n",
        "      predicted_sana_internet = np.argmax(model_clasification_leaves.predict(image_hoja_sana_internet), axis=-1)\n",
        "      label_to_text =  {1:'Enferma', 0:'Sana'}\n",
        "      text_prediction = label_to_text[predicted_sana_internet[0]]\n",
        "      print(\"Predicción es: \")\n",
        "      print(text_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QqLJqQNYexs"
      },
      "outputs": [],
      "source": [
        "# Probando otro modelo\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "# Bloquer la partie convolutionnelle du modèle pré-entraîné\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Ajouter les nouvelles couches pour la classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Construction du modèle final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m9uwZytYrDG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_generator, epochs=100, validation_data=valid_generator )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ZjpLDIpI3j"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vtg5CYqnfxsm"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_Test, y_Test)\n",
        "print('Accuracy en la fase de Test: {}'.format(score[1]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
