{"cells":[{"cell_type":"markdown","metadata":{"id":"qzXBieRM9Kfh"},"source":["# Paso #1: IMPORTAR LIBRERÍAS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9n57F309eOq"},"outputs":[],"source":["!wget https://www.dropbox.com/s/i4n134sqzu7psry/fotos%20procesadas.zip?dl=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HypAU829fn-"},"outputs":[],"source":["!wget https://www.dropbox.com/s/u5fu6o8285ebsne/Fotos%20TFM.zip?dl=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6v3JtBC9Kfm"},"outputs":[],"source":["!unzip Fotos\\ TFM.zip\\?dl\\=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KbaEe4kbIRZm"},"outputs":[],"source":["!unzip fotos\\ procesadas.zip\\?dl\\=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSLFlOkZ9Kfp"},"outputs":[],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMg3eqGX9Kfq"},"outputs":[],"source":["# Funciones y metodos reutilizables\n","def elem2dict(node):\n","    \"\"\"\n","    Convert an xml.ElementTree node tree into a dict.\n","    \"\"\"\n","    result = {}\n","\n","    for element in node:\n","        key = element.tag\n","        if '}' in key:\n","            # Remove namespace prefix\n","            key = key.split('}')[1]\n","\n","        if node.attrib:\n","            result['@attribs'] = dict(node.items())\n","\n","        # Process element as tree element if the inner XML contains non-whitespace content\n","        if element.text and element.text.strip():\n","            value = element.text\n","        else:\n","            value = elem2dict(element)\n","\n","        # Check if a node with this name at this depth was already found\n","        if key in result:\n","            if type(result[key]) is not list:\n","                # We've seen it before, but only once, we need to convert it to a list\n","                tempvalue = result[key].copy()\n","                result[key] = [tempvalue, value]\n","            else:\n","                # We've seen it at least once, it's already a list, just append the node's inner XML\n","                result[key].append(value)\n","        else:\n","            # First time we've seen it\n","            result[key] = value\n","\n","    return result\n","\n","def get_data_imgLabel(imgLabel):\n","    x = imgLabel[\"bndbox\"][\"xmin\"]\n","    y = imgLabel[\"bndbox\"][\"ymin\"]\n","    width = imgLabel[\"bndbox\"][\"xmax\"]\n","    height = imgLabel[\"bndbox\"][\"ymax\"]\n","\n","    return x,y, width, height\n","\n","# Funcion para redimensionar la imagen  a (512, 512)\n","# para redimensionar la imagen  a (512, 512)\n","def resize(x):\n","  return cv2.resize(x, dsize=(widthImage, heightImage), interpolation = cv2.INTER_AREA)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYYsXr5y9Kfr"},"outputs":[],"source":["# Importamos los paquetes necesarios\n","import pandas as pd\n","import numpy as np\n","import os\n","import PIL\n","import seaborn as sns\n","import pickle\n","from PIL import *\n","import cv2\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from IPython.display import display\n","from tensorflow.python.keras import *\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, optimizers\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import *\n","from tensorflow.keras import backend as K\n","from keras import optimizers\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import json\n","from xml.etree import ElementTree as ET\n","import random\n","from PIL import Image\n","\n","# Ruta de la data y capertas dentro de esta\n","dataPath = '/content/Fotos TFM'\n","dataPathXML = '/content/fotos procesadas'\n","typeLeavesList = os.listdir(dataPathXML)\n","\n","widthImage = 224\n","heightImage = 224\n","quantitytoProcess = 1000\n","counterSubPlot = 1\n","\n","# data\n","labels = []\n","leavesData = []\n","labelCounter = 0\n","\n","# Leemos la información de los Json en las carpetas, para obtener las coordenadas de las imagenes etiquetadas.\n","listCount = []\n","dataToProcess = []\n","\n","for nameDir in typeLeavesList:\n","    leavePathXML = dataPathXML + '/' + nameDir\n","    leavePathImg = dataPath + '/' + nameDir\n","\n","    if \"Sanas\" == nameDir:\n","      labelCounter = 0\n","\n","    if \"Enfermas\" == nameDir:\n","      labelCounter = 1\n","\n","    # lista de archivos .json con las etiquetas de las imagenes\n","    listXML =  [f for f in os.listdir(leavePathXML) if f.endswith('.xml')]\n","\n","    listXML = listXML[:quantitytoProcess]\n","\n","    countFilesXML = len([name for name in listXML ])\n","    print('Cantidad de imágenes:', nameDir)\n","    print(countFilesXML)\n","\n","    sample20ListXML = random.sample(listXML, 20)\n","\n","    # Cantidad de archivos a procesar\n","    listCount.append(countFilesXML)\n","\n","    for fileXML in listXML:\n","\n","        if len(list(filter(lambda x: x[\"label\"] == labelCounter, dataToProcess))) > quantitytoProcess:\n","            continue\n","\n","        xmlParsed = ET.parse(leavePathXML + '/'+ fileXML).getroot()\n","        xmlDict = elem2dict(xmlParsed)\n","        imageName = xmlDict[\"filename\"]\n","\n","        if \"object\" not in xmlDict:\n","            continue\n","\n","        objectImgLabel = xmlDict[\"object\"]\n","\n","        # Obtenemos la imagen completa\n","        image = cv2.imread(leavePathImg+'/'+ imageName)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if (type(objectImgLabel) == list):\n","            for imgLabel in objectImgLabel:\n","                x, y, width, height = get_data_imgLabel(imgLabel)\n","                roi = image[int(y):int(height), int(x):int(width)]\n","\n","                leafData = {\n","                    \"filenameImg\": imageName,\n","                    \"filenameXML\": fileXML,\n","                    \"label\" : labelCounter,\n","                    \"roi\": resize(roi)\n","                }\n","                dataToProcess.append(leafData)\n","\n","        else:\n","            x, y, width, height = get_data_imgLabel(objectImgLabel)\n","            roi = image[int(y):int(height), int(x):int(width)]\n","            leafData = {\n","                \"filenameImg\": imageName,\n","                \"filenameXML\": fileXML,\n","                \"label\" : labelCounter,\n","                \"roi\": resize(roi)\n","            }\n","            dataToProcess.append(leafData)\n","\n","\n","newListEnfermas = filter(lambda x: x[\"label\"] == 1, dataToProcess)\n","newListSanas = filter(lambda x: x[\"label\"] == 0, dataToProcess)\n","\n","listEnfermas = list(newListEnfermas)\n","listSanas = list(newListSanas)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tnwrVqZf2GJi"},"outputs":[],"source":["# # Mostrar las primeras 40 imágenes enfermas\n","fig = plt.figure(figsize=(15, 15))\n","\n","for i in range(40):\n","    image = listEnfermas[i][\"roi\"]\n","    ax = fig.add_subplot(5, 8, i + 1)\n","    ax.imshow(image)\n","    ax.axis(\"off\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmkOoWL44IQT"},"outputs":[],"source":["# # Mostrar las primeras 40 imágenes SANAS\n","fig = plt.figure(figsize=(15, 15))\n","\n","for i in range(40):\n","    image = listSanas[i][\"roi\"]\n","    ax = fig.add_subplot(5, 8, i + 1)\n","    ax.imshow(image)\n","    ax.axis(\"off\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52KwfEXh9Kfu"},"outputs":[],"source":["# Visualiacion de cantidad de imagenes por clasificación - Enfermas / Sanas\n","plt.figure(figsize = (5,5))\n","sns.barplot(x = typeLeavesList, y = listCount )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQWn-w5l9Kfv"},"outputs":[],"source":["print('Número de etiquetas 1 (Enfermas): ', len(listEnfermas))\n","print('Número de etiquetas 0(Sanas): ', len(listSanas))"]},{"cell_type":"markdown","metadata":{"id":"6KHZ7xmk9Kfx"},"source":["# Paso #3: PREPROCESADOR DE LAS IMÁGENES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETRCBnKI9Kfx"},"outputs":[],"source":["# Dividir el dataframe en características y etiquetas para la clasificación\n","from keras.utils import to_categorical\n","\n","X = np.array([x[\"roi\"] for x in dataToProcess])\n","y = to_categorical([x[\"label\"] for x in dataToProcess] )\n","\n","# # Visualizamos los pixeles de las imagenes\n","X[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pnJb6nje9Kfy"},"outputs":[],"source":["# Visualizamos las etiquetas\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0yt2UaW9Kfy"},"outputs":[],"source":["# Revisando la dimensionalidad de X\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ke3Du8oi9Kfz"},"outputs":[],"source":["X = np.stack(X, axis = 0)\n","# aqui era uno, pero algo ha pasado y se cambio a 3\n","X = X.reshape(len(listEnfermas)+len(listSanas) , 224, 224, 3)\n","\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeCfLOMO9Kfz"},"outputs":[],"source":["# Dividir el dataframe en conjunto de entrenamiento, test y validación\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Obtenemos el conjunto de entrenamiento y el conjunto de Test\n","X_train, X_Test, y_train, y_Test = train_test_split(X, y, test_size = 0.4, shuffle = True)\n","\n","# Del conjunto de Test, obtenemos una parte para el conjunto de validaciòn, el 50% del conjunto de Test\n","X_val, X_Test, y_val, y_Test = train_test_split(X_Test, y_Test, test_size = 0.6, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62QlYsREeU0k"},"outputs":[],"source":["# Limpiar memoria\n","del dataToProcess\n","del X\n","del y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5NDTFVc9Kfz"},"outputs":[],"source":["print(\"Conjunto de validación\")\n","print(X_val.shape, y_val.shape)\n","print(\"Conjunto de Test\")\n","print(X_Test.shape, y_Test.shape)\n","print(\"Conjunto de Entrenamiento\")\n","print(X_train.shape, y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"v3_vU2Eg9Kf0"},"source":["# Paso #4: NORMALIZACIÓN DE LOS DATOS Y PREPARACIÓN PARA EL ENTRENAMIENTO"]},{"cell_type":"markdown","metadata":{"id":"5J_wJKcX9Kf0"},"source":["# Paso #3: AUMENTACIÓN DE LAS IMÁGENES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vADmgAr39Kf1"},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    # rotation_range=90,\n","    # width_shift_range=0.05,\n","    # height_shift_range=0.2,\n","    # shear_range=0.2,\n","    # zoom_range=0.2,\n","    # horizontal_flip=True,\n","    # vertical_flip = True,\n","    brightness_range = [1.1, 1.15]\n","    )\n","\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=90,\n","    # width_shift_range=0.2,\n","    # height_shift_range=0.2,\n","    # shear_range=0.2,\n","    # zoom_range=0.2,\n","    # horizontal_flip=True,\n","    # vertical_flip = True,\n","    brightness_range = [1.1, 1.15]\n","    )\n","\n","\n","batch_size = 16\n","\n","valid_generator = valid_datagen.flow(\n","    X_val, y_val,\n","    batch_size=batch_size\n",")\n","train_generator = train_datagen.flow(\n","    X_train, y_train,\n","    batch_size=batch_size\n",")\n","\n","test_generator = test_datagen.flow(\n","    X_Test, y_Test,\n","    batch_size=batch_size\n",")"]},{"cell_type":"code","source":["# Probando otro modelo\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","\n","input_shape = (224, 224, 3)\n","num_classes = 2\n","batch_size = 16\n","\n","base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(128, activation='relu')(x)\n","predictions = Dense(num_classes, activation='softmax')(x)\n","\n","\n","model = Model(inputs=base_model.input, outputs=predictions)"],"metadata":{"id":"3JCKca1xW3kb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from time import gmtime, strftime\n","# Usamos la parada temprana para salir del entenamiento si el error de validación\n","# no decrece después de cierto número de epochs (paciencia)\n","earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n","fileTime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n","print(fileTime)\n","# Guardamos el mejor modelo con menor error de validación\n","checkpointer = ModelCheckpoint(\n","    filepath = \"/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/movilnet_weigth\"+fileTime+\".hdf5\",\n","    verbose = 1,\n","    save_best_only=True,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max')"],"metadata":{"id":"QaSSHFTeYB7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(train_generator, epochs=60, validation_data=valid_generator, callbacks=[checkpointer, earlystopping])\n"],"metadata":{"id":"bwr_eL5sXKmG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cu0XfnG59Kf1"},"source":["# TAREA #6: CONSTRUIR UN MODELO DE DEEP LEARNING(CNN) DE RESTNET(RED RESIDUAL)"]},{"cell_type":"code","source":["score = model.evaluate(X_Test, y_Test)\n","score_acurracy = score[1]\n","print('Accuracy en la fase de Test: {}'.format(score_acurracy))"],"metadata":{"id":"1M4iU_aZfDQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fileTime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n","print(fileTime)\n","model.save('/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/mode_mobilenet '+str(score_acurracy)+ \" --\"+fileTime+'.h5')"],"metadata":{"id":"1jd9poU9e-ou"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4npl0w5X0Tg"},"outputs":[],"source":["# Cargando Mejor Modelo Existente\n","\n","model_clasification_leaves = load_model(\"/content/drive/MyDrive/Master TFM/TFM/proyecto tfm/fotos procesadas/leaf_model Accuracy 0.978935718536377 --2023-07-09 15:04:06.h5\")\n","\n","score = model_clasification_leaves.evaluate(X_Test, y_Test)\n","print('Accuracy en la fase de Test: {}'.format(score[1]))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}